---
title: 机器学习西瓜书第二章
---

1. `!$ (C^{350}_{500})^2 $`
2. 10折交叉验证，也就是说用90个样本作为训练集，10个样本作为测试集。如果每个子集集都确实服从正反例各一半，那么学习算法的错误率的期望应该是50%，也就是在一个平均分布的样本中随机猜测。留一法总是有99个样本为训练集，1个样本为测试集，如果测试集的样本为正例，那么训练集一定是反例占多数，所以模型总是预测错误，所以错误率为100%。
3. 书上的P-R曲线实际上有点问题。如果三种算法在同一个数据集上测试的话，那么当召回率为1.0的时候，三种算法应该相交于同一个点，而且这个点所在的正确率不应该接近0。因为当召回率为1.0的时候，正确率实际上就是数据集中正样本的个数了，接近零表明这个数据集正样本的数量相较于负样本非常低。大多数情况应该是这样的，下面这张图说明数据集中有20%的样本是正例。

![P-R曲线][1]

现在说到书上的问题，F1值只是在某个阈值的设定下计算的，实际上和P-R曲线没有太大的关系。两个F1值不一样的分类器可能拥有相同的P-R曲线，只不过在不同的点上而已。所以BEP值没法判断。

4. 


  [1]: ./images/1505291302227.jpg